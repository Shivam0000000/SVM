{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba214d29-e336-46af-a59d-8b95e7d9b722",
   "metadata": {},
   "source": [
    "Q1. What is the relationship between polynomial functions and kernel functions in machine learning\n",
    "algorithms?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9729fe4f-27d8-492d-a859-4181413a3d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Polynomial functions and kernel functions in machine learning are related through their capacity to capture \n",
    "non-linear relationships in data. Polynomial functions are explicit mathematical expressions that involve powers \n",
    "and combinations of variables, commonly used in feature engineering to create polynomial features. For instance,\n",
    "in a 2D feature space, introducing polynomial features like X1^2 or X1*X2 can help capture non-linear patterns.\n",
    "\n",
    "Kernel functions, on the other hand, play a vital role in machine learning algorithms, such as Support Vector Machines\n",
    "(SVMs), for implicitly transforming data into higher-dimensional spaces without the need to explicitly calculate and \n",
    "store the transformed features. Polynomial kernel functions are a specific type of kernel that computes polynomial\n",
    "combinations of input features, resembling the polynomial features created during feature engineering.\n",
    "\n",
    "The relationship between them lies in the fact that polynomial kernel functions effectively perform the same type of \n",
    "non-linear transformations as polynomial features but do so implicitly and efficiently, making them suitable for \n",
    "high-dimensional data. Kernel functions, including polynomial kernels, enable SVMs to handle non-linear data by \n",
    "working in higher-dimensional spaces while avoiding the computational burden of explicitly expanding the feature space.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e6e290-cdab-4a51-834a-3847cb018b24",
   "metadata": {},
   "source": [
    "Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cea51d4-13f4-4cec-bd57-9aa0cf7bf3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To implement a Support Vector Machine (SVM) with a polynomial kernel in Python using Scikit-learn, \n",
    "follow these steps:\n",
    "\n",
    "Import Libraries:\n",
    "Import necessary libraries, including Scikit-learn components for SVM, dataset loading, data splitting,\n",
    "and performance evaluation.\n",
    "\n",
    "Load Data:\n",
    "Load a dataset suitable for classification. In this example, we use the Iris dataset as a demonstration.\n",
    "\n",
    "Split Data: \n",
    "Divide the dataset into training and testing sets to evaluate model performance accurately. The train_test_split \n",
    "function from Scikit-learn is commonly used for this purpose.\n",
    "\n",
    "Create SVM Classifier:\n",
    "Instantiate an SVM classifier with the desired kernel. Specify the kernel as 'poly' to indicate a polynomial \n",
    "kernel. You can also set the polynomial kernel's degree using the degree parameter.\n",
    "\n",
    "Train Classifier:\n",
    "Fit the SVM classifier on the training data using the fit method.\n",
    "\n",
    "Make Predictions:\n",
    "Use the trained classifier to make predictions on the test data with the predict method.\n",
    "\n",
    "Evaluate Performance:\n",
    "Assess the model's performance by calculating a performance metric, such as accuracy, comparing the predicted\n",
    "labels to the true labels.\n",
    "\n",
    "Adjust Hyperparameters:\n",
    "Experiment with different polynomial degrees and other hyperparameters to optimize model performance based on\n",
    "cross-validation or other evaluation techniques.\n",
    "\n",
    "This implementation allows you to harness the power of polynomial kernels in SVMs to capture complex non-linear\n",
    "relationships in your data for classification tasks.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761d13f4-b302-4fbd-be57-eaa8bf651354",
   "metadata": {},
   "source": [
    "Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c6b9f4-dcaa-4ea4-afa7-06b3d9e1bb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In Support Vector Regression (SVR), epsilon serves as a crucial parameter that influences the width of the\n",
    "margin, which, in turn, affects the number of support vectors. Support vectors are data points that directly\n",
    "influence the regression model and lie either within the margin or on the wrong side of it.\n",
    "\n",
    "Increasing the value of epsilon, referred to as a wider margin, results in a more permissive model that allows\n",
    "larger errors. In this scenario, the SVR prioritizes generalization over precise fitting. Fewer data points are\n",
    "classified as support vectors because the model permits greater deviations from the regression line.\n",
    "\n",
    "Conversely, reducing epsilon, creating a tighter margin, enforces a stricter error tolerance, and the SVR endeavors \n",
    "to fit the training data more closely. As a consequence, more data points may become support vectors as the model\n",
    "attempts to minimize errors within the narrow margin.\n",
    "\n",
    "The choice of epsilon in SVR involves a trade-off: a larger epsilon favors simplicity and generalization, while a \n",
    "smaller epsilon emphasizes fitting the training data more accurately but may lead to overfitting. Selecting the\n",
    "appropriate epsilon depends on the specific problem and the balance between model complexity and performance.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd20714-6cad-44c4-ade7-46a3ef174ade",
   "metadata": {},
   "source": [
    "Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter\n",
    "affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works\n",
    "and provide examples of when you might want to increase or decrease its value?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08d928e-af05-4177-a4af-824b4d2d667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The performance of Support Vector Regression (SVR) is heavily influenced by the choice of kernel function, C parameter,\n",
    "epsilon parameter, and gamma parameter:\n",
    "\n",
    "Kernel Function:\n",
    "The kernel function determines the transformation applied to the data to capture non-linear patterns. Selecting the\n",
    "appropriate kernel is essential for modeling complex relationships in the data. For instance, using an RBF kernel\n",
    "is beneficial when data exhibits intricate non-linearities.\n",
    "\n",
    "C Parameter:\n",
    "The C parameter regulates the trade-off between model complexity and training error. A higher C leads to a narrower\n",
    "margin, potentially overfitting noisy data, while a lower C allows a wider margin, prioritizing generalization.\n",
    "\n",
    "Epsilon Parameter:\n",
    "Epsilon defines the margin's width, affecting the tolerance for deviations from the regression line. Increasing \n",
    "epsilon permits a larger margin and robustness to noise, while decreasing epsilon tightens the margin for precise \n",
    "fitting to training data.\n",
    "\n",
    "Gamma Parameter:\n",
    "In RBF kernels, Gamma controls the kernel's shape and flexibility. Smaller gamma values result in broader, smoother kernels,\n",
    "while larger Gamma values lead to narrower, more peaked kernels. Careful selection of Gamma is crucial for handling \n",
    "high-dimensional data and avoiding overfitting.\n",
    "\n",
    "The optimal parameter values depend on the specific dataset and the trade-offs you are willing to make. Cross-validation \n",
    "and experimentation are often necessary to find the right combination for optimal SVR performance.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d8b683-a5cc-4dfd-b218-b85b1015b373",
   "metadata": {},
   "source": [
    "Q5. Assignment:\n",
    "    \n",
    "Import the necessary libraries and load the dataset\n",
    "\n",
    "Split the dataset into training and testing sets\n",
    "\n",
    "Preprocess the data using any technique of your choice (e.g. scaling, normalization)\n",
    "\n",
    "Create an instance of the SVC classifier and train it on the training data\n",
    "\n",
    "Use the trained classifier to predict the labels of the testing data\n",
    "\n",
    "Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy,\n",
    "precision, recall, F1-score)\n",
    "\n",
    "Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomizedSearchCV to\n",
    "improve its performance\n",
    "\n",
    "Train the tuned classifier on the entire dataset\n",
    "\n",
    "Save the trained classifier to a file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9568c506-5fe6-41b8-9983-867f536a5950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries and load the dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df=sns.load_dataset('geyser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57d3a88f-6cbd-4859-a26c-4553a6dd2c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>waiting</th>\n",
       "      <th>kind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.600</td>\n",
       "      <td>79</td>\n",
       "      <td>long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.800</td>\n",
       "      <td>54</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.333</td>\n",
       "      <td>74</td>\n",
       "      <td>long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.283</td>\n",
       "      <td>62</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.533</td>\n",
       "      <td>85</td>\n",
       "      <td>long</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  waiting   kind\n",
       "0     3.600       79   long\n",
       "1     1.800       54  short\n",
       "2     3.333       74   long\n",
       "3     2.283       62  short\n",
       "4     4.533       85   long"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb0af54c-6c16-4e41-b598-748185b2da15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X=df.drop('kind',axis=1)\n",
    "encoder=LabelEncoder()\n",
    "y=encoder.fit_transform(df['kind'])\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.20,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bdee5d1-6e3f-47e4-91d2-9da348f5a5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data using any technique of your choice (e.g. scaling, normalization)\n",
    "\n",
    "scaler=StandardScaler()\n",
    "X_train_scaled=scaler.fit_transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b759cb09-adba-4f35-9ef9-172c8633274d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create an instance of the SVC classifier and train it on the training data\n",
    "svc=SVC(kernel='linear')\n",
    "svc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "347726a0-0287-4f72-88bf-fcf99c42ee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained classifier to predict the labels of the testing data\n",
    "y_pred=svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df1ce555-c244-4be1-b049-902b6c92e12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35  0]\n",
      " [ 0 20]]\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        35\n",
      "           1       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        55\n",
      "   macro avg       1.00      1.00      1.00        55\n",
      "weighted avg       1.00      1.00      1.00        55\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy,recision, recall, F1-score)\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "\n",
    "print(confusion_matrix(y_pred,y_test))\n",
    "print(accuracy_score(y_pred,y_test))\n",
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f36c305-90df-4fe4-8ed0-a101d52e5c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomizedSearchCV to improve its performance\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param={'C':[1.0,10,100],\n",
    "        'kernel':['linear', 'poly', 'rbf'],\n",
    "         'gamma':['scale','auto']}\n",
    "\n",
    "clf=RandomizedSearchCV(SVC(),param_distributions=param,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac401288-2593-458e-b64c-eb00fc974ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35  0]\n",
      " [ 0 20]]\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        35\n",
      "           1       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        55\n",
      "   macro avg       1.00      1.00      1.00        55\n",
      "weighted avg       1.00      1.00      1.00        55\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the tuned classifier on the entire dataset\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred4=clf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_pred4,y_test))\n",
    "print(accuracy_score(y_pred4,y_test))\n",
    "print(classification_report(y_pred4,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0aad252-c482-4280-ad94-542b2123eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained classifier to a file for future use.\n",
    "import pickle\n",
    "pickle.dump(clf,open('classifier.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
